{"posts":[{"title":"Rocket基本概念：","content":"2. Rocket基本概念 Producer:消息的发送者；举例：发信者 Consumer:消息接收者；举例：收信者 Broker:暂存和传输消息；举例：邮局 NameServer:管理Broker;举例：各个邮局的管理机构 Topic:区分消息的种类；一个发送者可以发送消息给一个或者多个Topic;一个消息的接收者可以订阅一个或者多个Topici消息 Message Queue:相当于是Topic的分区；用于并行发送和接收消息 3. Rocket的消息类型 3.1 按照发送的特点分： 3.1.1 同步发送 a.同步发送，线程阻塞，投递completes阻塞结束 b.如果发送失败，会在默认的超时时间3秒内进行重试，最多重试2次 c.投递completes不代表投递成功，要check SendResult.sendStatus来判断是否投递成功 d.SendResult!里面有发送状态的枚举：SendStatus,同步的消息投递有一个状态返回值的 e.retry的实现原理：只有ack的SendStatus=SEND_OK才会停止retry 注意事项：发送同步消息且Ack为SEND OK,只代表该消息成功的写入了MQ当中，并不代表该消息成功的被Consumeri消费了。 3.1.2 异步发送 a.异步调用的话，当前线程一定要等待异步线程回调结束再关闭producer啊，因为是异步的，不会阻塞，提前关闭producer会导致未回调链接就断开了 b.异步消息不retry,投递失败回调onException(0方法，只有同步消息才会retry,源码参考DefaultMQProducerlmpl.class C.异步发送一般用于链路耗时较长，对T响应时间较为敏感的业务场景，例如用户视频上传后通知启动转码服务，转码完成后通知推送转码结果等。 3.1.3 单向发送 a.消息不可靠，性能高，只负责往服务器发送一条消息，不会重试也不关心是否发送成功 b.此方式发送消息的过程耗时非常短，一般在微秒级别 3.2 按照发送的特点分： 3.2.1 普通消息（订阅） 普通消息是我们在业务开发中用到的最多的消息类型，生产者需要关注消息发送成功即可，消费者消费到消息即可，不需要保证消息的顺序，所以消息可以大规模并发地发送和消费，吞吐量很高，适合大部分场景。 3.2.2 顺序消息 顺序消息分为分区顺序消息和全局顺序消息，全局顺序消息比较容易理解，也就是哪条消息先进入，哪条消息就会先被消费，符合我们的FIFO,很多时候全局消息的实现代价很大，所以就出现了分区顺序消息。分区顺序消息的概念可以如下图所示： 3.2.3 延时消息 - 作用：订单超时库存归还 延迟的机制是在服务端实现的，也就是 Broker 收到了消息，但是经过一段时间以后才发送服务器按照1-N定义了如下级别：“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”;若要发送定时消息，在应用层初始化Messagei消息对象之后，调用Message.setDelayTimeLevel(int level)方法来设置延迟级别，按照序列取相应的延迟级别，例如level=2,则延迟为5s 实现原理： a.发送消息的时候如果消息设置了DelayTimeLevel,那么该消息会被丢到 ScheduleMessageService.SCHEDULE_TOPIC这个Topic.里面 b.根据DelayTimeLeveli选择对应的queue c.再把真实的topici和queue信息封装起来，set到msg里面 d.然后每个SCHEDULE_TOPIC_XXXX的每个DelayTimeLevelQueue,有定时任务去刷新6i是否有待投递的消息 e.每10s定时持久化发送进度 3.2.4 事务消息 https://help.aliyun.com/document_detail/43348.html?spm=a2c4g.11186623.2.16.78ee6192siK1qV#concept-2047067 消息队列RocketMQ版提供的分布式事务消息适用于所有对数据最终一致性有强需求的场景。本文介绍消息队列 RocketMQ版事务消息的概念、优势、典型场景、交互流程以及使用过程中的注意事项。 概念介绍 事务消息：消息队列RocketMQ版提供类似X或Open XA的分布式事务功能，通过消息队列RocketMQ版事务消息能达到分布式事务的最终一致。 半事务消息：暂不能投递的消息，发送方已经成功地将消息发送到了消息队列RocketMQ版服务端，但是服务端未收到生产者对该消息的二次确认，此时该消息被标记成“暂不能投递”状态，处于该种状态下的消息即半事务消息。 消息回查：由于网络闪断、生产者应用重启等原因，导致某条事务消息的二次确认丢失，消息队列RocketMQ版服务端通过扫描发现某条消息长期处于“半事务消息”时，需要主动向消息生产者询问该消息的最终状态(Commit或是Rollback),该询问过程即消息回查。 分布式事务消息的优势 消息队列RocketMQ版分布式事务消息不仅可以实现应用之间的解耦，又能保证数据的最终一致性。同时，传统的大事务可以被拆分为小事务，不仅能提升效率，还不会因为某一个关联应用的不可用导致整体回滚，从而最大限度保证核心系统的可用性。在极端情况下，如果关联的某一个应用始终无法处理成功，也只需对当前应用进行补偿或数据订正处理，而无需对整体业务进行回滚。 ","link":"https://hzqyihui.github.io/post/rocket-ji-ben-gai-nian/"},{"title":"Rocket安装和配置","content":"1. 单独进行Docker安装 1.1 server 有日志目录映射 1.2 broker 目录映射 注意 如果你的微服务或者项目在开发的时候没有放入 docker中或者与rocketmq容器不能直接用IP访问， 那么请把broker.conf中的 1.3 console broker 配置文件 2. 官网二进制包安装 2.1 安装RocketMQ 2.2 安装RocketMQ-dashboard （数据看板） 2.3 启动NameServer​ 安装完RocketMQ包后，我们启动NameServer 2.4 启动Broker NameServer成功启动后，我们启动Broker 2.5 消息收发(测试) 在进行消息收发之前，我们需要告诉客户端NameServer的地址，RocketMQ有多种方式在客户端中设置NameServer地址，这里我们利用环境变量 NAMESRV_ADDR 2.6 关闭服务器 ","link":"https://hzqyihui.github.io/post/rocket-an-zhuang-he-pei-zhi/"},{"title":"Dockerfile 的语法使用：","content":"制作镜像： 制作镜像： Docker多阶段编译 如果要从一个镜像直接复制到另一个镜像： 使用alpine镜像，能够极大的缩小镜像，容器的大小。 ","link":"https://hzqyihui.github.io/post/dockerfile-de-yu-fa-shi-yong/"},{"title":"HTTP版本：","content":"版本： HTTP 1.0 : 已废弃 HTTP 1.1 ： 2.1 HTTP 1.1 使用了摘要算法进行身份验证 2.2 默认使用了长连接，长连接就是只需要一次建立就可以传输多次数据，传输完成后，只需要一次切断连接即可。长连接的连接时长可以通过请求头中的 keep-alive 来设置 2.3 新增了 e-tag If-Unmodified-Since If-Match If-None-Match 等缓存控制标头来控制缓存失效。 2.4 支持断点续传，通过使用请求头中的range 来实现 2.5 使用了虚拟网络，在一台物理服务器上可以存在多个虚拟主机，并且他们共享一个IP地址。 HTTP 2.0 3.1 2015年开发出来的标准，主要做出以下改变。 3.2 头部压缩：由于HTTP 1.1 经常会出现User-Agent, Cookie， Accept，Server，Range等字段可能会占用几百甚至几千字段，而Body却经常只有几十字节，所以导致头部偏重。HTTP 2.0 使用HPACK算法进行压缩。 3.3 二进制格式：HTTP2.0 使用了更加靠近TCP/IP的二进制格式，而抛弃了ASCII码，提升了解析效率。 3.4 强化安全，由于安全已成为重中之重，所以HTTP 2.0 一般都跑在HTTPS 上的。 3.5 多路复用：即每个请求都是用作连接共享。一个请求对应一个id，这样一个连接上可以有多个请求。 HTTPS与HTTP的一些区别 HTTPS协议需要到CA申请证书，一般免费证书很少，需要交费。 HTTP协议运行在TCP之上，所有传输的内容都是明文，HTTPS运行在SSL/TLS之上，SSL/TLS运行在TCP之上，所有传输的内容都经过加密的。 HTTP和HTTPS使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 HTTPS可以有效的防止运营商劫持，解决了防劫持的一个大问题。 https://zhuanlan.zhihu.com/p/135947893 ","link":"https://hzqyihui.github.io/post/http-ban-ben/"},{"title":"HTTP请求响应过程：","content":"输入网址后，到拿到结果，发生了什么？ DNS服务器会首先进行域名映射，（第一步是现在电脑本地hosts文件查找，是否能找到，若不能找到，则请求DNS），找到IP地址后，HTTP客户端进程在80端口发起一个到IP对应服务器的TCP链接。 HTTP客户端通过他的套接字向服务器发送一个HTTP请求报文。该报文中包含了 资源路径。 HTTP服务器通过他的套接字，接受了该报文，进行请求的解析工作，并从其存储器（RAM或磁盘）中检索出对象，然后把检索出来的对象进行封装，封装到HTTP响应报文中，闭关通过套接字向客户进行发送。 HTTP服务器随机通知TCP断开TCP连接，实际上是需要等到客户接受完响应报文后才会断开TCP连接。 HTTP客户端接受完响应报文后，TCP连接会关闭。HTTP客户端从响应中提取出报文是一个HTML响应文件，并检查该HTML文件，然后循环检查报文中其他对象 检查完成后，HTTP客户端会把对应的资源通过显示器呈现给用户。 HTTP协议主要由三大部分组成： 起始行：描述请求或响应的基本信息 头部字段：使用key-value 形式更详细的说明报文 消息正文：实际传输的数据，他不一定是纯文本，可以是图片，视频等二进制数据。 每个报文的起始行都是有三个字段组成：请求方法（GET POST），URL字段， HTTP版本字段。 HTTP1.1 ** 第一个问题：现代浏览器在与服务器建立了一个 TCP 连接后是否会在一个 HTTP 请求完成后断开？什么情况下会断开？ ** 默认情况下建立 TCP 连接不会断开，只有在请求报头中声明 Connection: close 才会在请求完成后关闭连接。（详细文档见下面的链接） 第二个问题：一个 TCP 连接可以对应几个 HTTP 请求？ 了解了第一个问题之后，其实这个问题已经有了答案，如果维持连接，一个 TCP 连接是可以发送多个 HTTP 请求的。 第三个问题：一个 TCP 连接中 HTTP 请求发送可以一起发送么（比如一起发三个请求，再三个响应一起接收）？ 在 HTTP/1.1 存在 Pipelining 技术可以完成这个多个请求同时发送，但是由于浏览器默认关闭，所以可以认为这是不可行的。在 HTTP2 中由于 Multiplexing 特点的存在，多个 HTTP 请求可以在同一个 TCP 连接中并行进行。 第四个问题：为什么有的时候刷新页面不需要重新建立 SSL 连接？ 在第一个问题的讨论中已经有答案了，TCP 连接有的时候会被浏览器和服务端维持一段时间。TCP 不需要重新建立，SSL 自然也会用之前的。 第五个问题：浏览器对同一 Host 建立 TCP 连接到数量有没有限制？ 假设我们还处在 HTTP/1.1 时代，那个时候没有多路传输，当浏览器拿到一个有几十张图片的网页该怎么办呢？肯定不能只开一个 TCP 连接顺序下载，那样用户肯定等的很难受，但是如果每个图片都开一个 TCP 连接发 HTTP 请求，那电脑或者服务器都可能受不了，要是有 1000 张图片的话总不能开 1000 个TCP 连接吧，你的电脑同意 NAT 也不一定会同意。 所以答案是：有。Chrome 最多允许对同一个 Host 建立六个 TCP 连接。不同的浏览器有一些区别。 ","link":"https://hzqyihui.github.io/post/http-qing-qiu-xiang-ying-guo-cheng/"},{"title":"sed命令：","content":"sed命令： inux sed 命令是利用脚本来处理文本文件。 sed 可依照脚本的指令来处理、编辑文本文件。 Sed 主要用来自动编辑一个或多个文件、简化对文件的反复操作、编写转换程序等。 语法 参数说明： -e &lt;script&gt;或 --expression= &lt;script&gt; 以选项中指定的script来处理输入的文本文件。 -f&lt;script文件&gt;或--file=&lt;script文件&gt; 以选项中指定的script文件来处理输入的文本文件。 -h或--help 显示帮助。 -n或--quiet或--silent 仅显示script处理后的结果。 -V或--version 显示版本信息。 动作说明： a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～ c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！ d ：删除，因为是删除啊，所以 d 后面通常不接任何东东； i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)； p ：打印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～ s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正则表达式！例如 1,20s/old/new/g 就是啦！ 比如 sed 的查找与替换的与 vi 命令类似，语法格式如下： g 标识符表示全局查找替换，使 sed 对文件中所有符合的字符串都被替换，修改后内容会到标准输出，不会修改原文件： 选项 i 使 sed 修改文件: 批量操作当前目录下以 test 开头的文件： ","link":"https://hzqyihui.github.io/post/sed-ming-ling/"},{"title":"xargs命令：","content":"xargs： -i 或者是-I，这得看linux支持了，将xargs的每项名称，一般是一行一行赋值给 {}，可以用 {} 代替。 ","link":"https://hzqyihui.github.io/post/xargs-ming-ling/"},{"title":"firewall命令（防火墙）：","content":"1、firewalld的基本使用 启动： systemctl start firewalld 查看状态： systemctl status firewalld 停止： systemctl disable firewalld 禁用： systemctl stop firewalld 2.systemctl是CentOS7的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体。 启动一个服务：systemctl start firewalld.service 关闭一个服务：systemctlstop firewalld.service 重启一个服务：systemctlrestart firewalld.service 显示一个服务的状态：systemctlstatus firewalld.service 在开机时启用一个服务：systemctlenable firewalld.service 在开机时禁用一个服务：systemctldisable firewalld.service 查看服务是否开机启动：systemctlis-enabled firewalld.service 查看已启动的服务列表：systemctllist-unit-files|grep enabled 查看启动失败的服务列表：systemctl--failed 3.配置firewalld-cmd 查看版本： firewall-cmd --version 查看帮助： firewall-cmd --help 显示状态： firewall-cmd --state 查看所有打开的端口： firewall-cmd--zone=public --list-ports 更新防火墙规则： firewall-cmd --reload 查看区域信息: firewall-cmd--get-active-zones 查看指定接口所属区域： firewall-cmd--get-zone-of-interface=eth0 拒绝所有包：firewall-cmd --panic-on 取消拒绝状态： firewall-cmd --panic-off 查看是否拒绝： firewall-cmd --query-panic 那怎么开启一个端口呢 添加 重新载入 查看 删除 查看firewall是否运行,下面两个命令都可以 查看当前开了哪些端口 其实一个服务对应一个端口，每个服务对应/usr/lib/firewalld/services下面一个xml文件。 查看还有哪些服务可以打开 查看所有打开的端口： 更新防火墙规则： ","link":"https://hzqyihui.github.io/post/firewall-ming-ling-fang-huo-qiang/"},{"title":"nohup 命令：","content":"nohup 命令，no hang up（不挂起），用于在系统后台不挂断地运行命令，退出终端不会影响程序的运行。 最后的 &amp; 是指 后台运行， 2&gt;&amp;1 解释： 将标准错误 2 重定向到标准输出 &amp;1 ，标准输出 &amp;1 再被重定向输入到 runoob.log 文件中。 0 – stdin (standard input，标准输入) 1 – stdout (standard output，标准输出) 2 – stderr (standard error，标准错误输出) ","link":"https://hzqyihui.github.io/post/nohup-ming-ling/"},{"title":"安装 FFmpeg：","content":"首次安装 FFmpeg 后，虽然能对音视频进行一些处理，但是 该软件默认 不包含 h264 的编码器，导致若 想编码为 h264的 视频，就会报错。Unknown encoder ‘h264’ ，h264 视频编码的 格式 是能直接在 浏览器 video 标签中直接播放的视频。 源码安装流程： fmpeg安装第三方编码器（encoder）库，ffmpeg编码h264（完） ffmpeg安装第三方编码器（encoder）库 关键词：ffmpeg、编码h264、第三方encoder 安装好了ffmpeg后，如果你使用ffmpeg工具去把某个视频文件转成h264视频编码、mp3音频编码or其他ffmpeg自身不带的xxx编码类型，就会看到报错信息，unknown encoder 'xxx'。此刻你需要的只要去安装其他的编码器就行了，本质上其实是把其他的编码器以库的形式安装好，例如，把正确的libx264.so or libx264.a存放在/usr/lib下 or /usr/local/lib下。 举两个例子吧，视频方面的编码器就拿h264来说，音频方面的例子就拿mp3（mp3lame）来说。 扫盲，Linux下安装一个正规的软件，一般都是三部曲，①、【./configure】（加一些可能的参数，比如enable一些功能，disable一些功能，究竟有哪些功能可以开启和关闭呢？一般通过./configure --help命令来查询），②、【make】（编译），③、【sudo make install】（把生成的二进制应用程序文件和.so和.a复制到/usr/local/下） 一、h264 动手搜一下ffmpeg的工程代码库，会发现每个codec都有一下几个成员变量，但是有好几个codec缺少encoder，h264就是其中一个了。先不管什么原因，ffmpeg没有原生的支持h264，但是你可以查看一下avcodec_register_all这个API，会发现一大片的REGISTER_ENCODER(XXX, xxx) REGISTER_DECODER(XXX, xxx) 这里分很多块，例如/* video codecs /，/ audio codecs /，/ external libraries / 但是你在/ video codecs /这一块却看不到h264的REGISTER_ENDECODER (H264, h264);这句话，如果你坚持往下翻，你会在/ external libraries */这块里面发现REGISTER_ENCODER (LIBX264, libx264);所以ffmpeg是有给h264准备好了接口的，但是需要第三方库来支持。 回到重点，怎么装呢？ 1.先下载x264的工程代码，【git clone git://git.videolan.org/x264.git】。 2.进入x264目录，然后./configure --help看看它的帮助信息，我们这里需要的是x264以.so or .a的形式来支援ffmpeg，所以一般就关注shared和static关键词就可以了。执行./configure --enable-shared --enable-static就行了。 3.完了make &amp;&amp; sudo make install就可以了。 你会发现我们在./configure的时候没有指定前缀--prefix=/usr，很明显，libx264.so和libx264.a就会复制到/usr/local/lib下去，记住这里，等下会因为这里要做一些修改。 二、mp3lame 上面说了h264，相信mp3lame理解起来就简单多了。 1.先下载mp3lame的工程代码，http://sourceforge.net/projects/lame/files/lame/，为什么这里要显得多余的讲一下mp3lame呢，是这样的。大家可以看到x264用的是git，mp3lame是用的sourceforge，不妨再多说一个faac（也是一种原生ffmpeg不支持的音频codec），faac用的是http://sourceforge.net/projects/faac/files/faac-src/，所以每一种codec或者很重要的软件都有一个团队或者社区在维护，所以需要什么东西，尽量去sourceforge或者git上找，其他地方找的可能不够新，可能不完整不正确。 2.然后也是./configure --help先，看看哪些功能是我们需要打开关闭的 3.完了make &amp;&amp; sudo make install就可以了。 很明显，我们又没有指定--prefix-/usr，所以mp3lame的libmp3lame.so和libmp3lame.a就被赋值到了/usr/local/lib下了。 三、重新编译ffmpeg 1.进入ffmpeg目录，./configure --enable-gpl --enable-libx264 --enable-libmp3lame，然后就生成了新的makefile了。 2.执行sudo make clean &amp;&amp; make sudo make install。 3.这样ffmpeg就被重新编译了，完了就可以验证一下，使用ffmpeg工具，把某个视频文件中的视频流转码成h264格式，音频流转码成mp3lame格式，不妨试试。 4.如果你真的尝试了，你应该会看到类似于“libxxx.so找不到”的错误提示，解决办法如下： （1）.表象：ffmpeg运行的时候试图去链接libxxx.so，但是却找不到相应的libxxx.so。 （2）.疑惑：我之前明明安装了libxxx.so的。 （3）.原因：程序运行的时候默认是去/usr/lib下找libxxx.so，但是我们之前安装的确实在/usr/local/lib下，所以造成这个报错。 （4）.解决办法：有很多，我说一种我亲测过的。 在/etc/ld.so.conf文件中添加一行/etc/ld.so.conf，当然是用root用户啦。然后执行ldconfig命令使得刚才的修改生效，完了再运行ffmpeg的转码命令试试，可以了吧。 之前我尝试过用ffplay来播放一个h264编码的视频，结果当然是可以播放，我就天真的以为ffmpeg支持h264了，其实不然，ffmpeg主要还是用来解码，所以部分格式的encoder却没有，所以才会有第三方库支援，为什么原生ffmpeg不支持某些格式呢？原因我暂时不知道。为了解决ffmpeg可以编码h264这个问题，我在网上搜索一些资料，然后总结成上文，在此过程中我还收获了一些Linux的知识，也已经写出。 补充三点： aac：./configure --enable-shared --enable-static 264：./configure --enable-shared --enable-static --disable-asm ffmpeg：./configure --enable-gpl --enable-libx264 --enable-libfaac --enable-nonfree --disable-yasm ","link":"https://hzqyihui.github.io/post/an-zhuang-ffmpeg/"},{"title":"umask命令：","content":"对于root用户，他的umask值是022。当root用户创建目录时，默认的权限就是用最大权限777去掉相应位置的umask值权限，即对于所有者不必去掉任何权限，对于所属组要去掉w权限，对于其他用户也要去掉w权限，所以目录的默认权限就是755；当root用户创建文件时，默认的权限则是用最大权限666去掉相应位置的umask值，即文件的默认权限是644。 umask命令只能临时修改umask值，系统重启之后umask将还原成默认值。如果要永久修改umask值，需要修改/etc/profile文件或是修改/etc/bashrc文件，例如要将默认umask值设置为027，那么可以在文件中增加一行“umask 027”。 /etc/profile和/etc/bashrc都可以用于设置用户登录系统时自动执行某些操作，他们的区别是/etc/profile只在用户第一次登录时被执行，而/etc/bashrc则在用户每次登录加载Bash Shell时都会被执行。 因而，如果是修改/etc/profile文件，将只对新创建的用户生效；而如果是修改/etc/bashrc文件，则对所有用户都生效。 ","link":"https://hzqyihui.github.io/post/umask-ming-ling/"},{"title":"shell 笔记：","content":" shell脚本中 某些符号代表什么意思： 举例说明： 以上脚本，当执行了 ps 后， 本意是 要去匹配是否存在 java -jar dhcamera 的进程， 若发现运行着， 则 ps 这个操作是正确的， 那么 $? 就是这个 退出的状态，当为 0时，正确。 不为0，则错误，即未匹配到任何值，则执行 if 语句块中的 语句 ","link":"https://hzqyihui.github.io/post/shell-bi-ji/"},{"title":"GIT分支与工作流","content":"分支的概念： 往简单说： 就是开发过程中，不同的程序员走不通的路，做不同的事情，这是分支的概念。（岔路口） 官方一点：Git 的分支，其实本质上仅仅是指向提交对象的可变指针，这个可变指针，指向路的终点。如我上次讲的，建立一个Git分支，实际上就是在 .git\\refs\\heads 文件夹下继续建立文件夹或者文件，文件内部是基于的某个分支的最新Head提交对象。 分支的作用： 分支的作用主要在于，对同一个项目，需要同时开发不同的需求，这个时候就需要不同的分支来管理了。 忌讳： Git分支不是代码仓库，其本质只是一个 commit 对象（上节 git核心原理 有提到），Git分支不同于SVN等集中式版本管理工具，SVN的分支有一个拷贝的概念在里面，每一个分支都是一份完整的备份。有些地方就会利用 SVN 的分支来管理不同的仓库。但 分支仍然不应该这么使用。 原因：分支始终有一个合并的概念，若不同分支存储不同仓库，这个合并的操作就无法完成（俩仓库八竿子打不着的关系）。 操作： 通常基于 master/develop 切不同的分支出来，最后开发完成后，合并到某一个分支。该分支即完成使命。 当前现象： 因为现在我们的需求都是由PM一次性给到，一般来说做的需求都比较大，代码新增，更新量都比较大，这就导致多个人在一起并在一个分支开发。 哪种情况出现并行开发：PM出需求频繁，但都是小需求，对哪里进行修改，对哪里进行新增，需要快速上线的话，就可以切出一个分支进行开发，配合使用Jenkins（+Ansible），以达到持续集成+持续部署的目的。 工作流： ​ 在介绍工作流之前首先认识下GIT的几个功能，Issue, Pull Request, Fork。这几个功能在团队协作规范的工作流中都起了相应的作用。下面介绍下各自所处的位置与作用。 Issue： Issue是一个记录的平台。对拥有者来说，可以写下一步的工作计划，或者写某个线上的BUG，需要修复并且记录在这里。而对其他可读的用户来说，就是一个提出问题的平台，用户提出问题，拥有者查看后，进行问题的排查。所以根据我们现在对GIT 提交记录的要求，当使用 fix 或 close时，就可以标记为 close #n或 fix #n，这里的n代表的是问题的id,也就是下面链接中的2 Pull Request Pull Request 在Coder中的流行叫法是PR，中文名叫合并请求，它的作用是 基于某个分支，比对另一个分支的代码，以此来查看哪些人提交了代码，代码变更的详细和多少。如下图所示： 以上可以看到这些是一些普通的变更代码。这样的话，我们就可以实现组内的Code Review，也就是同事之间相互审核代码。PR的作用不仅于此，当一个人没有权限针对某个分支Push代码的时候，就可以提交PR，由有Write权限的人进行合并，合并后代码即进入到目标分支。常见的使用场景：开发完功能分支后，创建一个PR到master，等QA验证完成后，即可合并。 Fork Fork中文名派生，作用就是把一个其它组织的仓库给完全复刻到个人帐号下面。派生后，两个仓库之间就没有关系了。如还需要同步原仓库代码，可以通过反向PR（似乎Gogs不提供，Github有），进行代码合并；或创建一个新的远端地址，指向原仓库。如下图所示：Fork 在某些场景下十分有用。在单身网站Github上有太多的开源项目，当我们对某一个进行派生后，后面发现了一个BUG，并对其进行了修改，你就可以创建PR到原仓库（对方开启PR权限的情况下），原仓库拥有者看到后，经考虑，对方就可以进行合并操作，你的代码就进入了原仓库。这也就是所谓的开源社区贡献。如下图所示： ​ 以上的功能或特性其实在一些工作流中都有用到。 当前流行的Git工作流： Git Flow Feature Branch Flow Forking Flow Git Flow: ​ 在这种工作流中会长期存在两个分支，分别是 master 和 develop，同时还会存在其它类型的短期分支，如：feature, release, hotfix。下面来主要介绍下该种团队工作流方式，同时结合我们自己的工作流，进行相应的对比，以找出可以借鉴与需要改善的地方。 master分支： master分支只会保存稳定上线的代码，而不应该作为一个可以被随意合并的分支用。当对master分支进行PR合并**（master分支不应该被直接合并，而应该通过创建PR的方式进行合并（仍然视情况而定））操作的时候，也就代表着代码已经可以上线了，或者已经上过线了（此处的两种说法决定了合并代码与上线操作的顺序，后面讲）**。合并操作之后，即可进行打tag的操作， 也就是说master分支的代码应只用作tag分配版本号使用，不应做任何修改与直接合并用。 develop分支：develop分支是一个功能的集成分支，通常也叫开发分支。它应该始终大于等于master分支的提交，我们平时开发不应该在该分支进行开发，该分支只作为合并代码用，这也和上面master分支相呼应。既然不能在develop分支直接开发，那么就得存在一个额外的分支来进行开发，由此牵引出下面这个分支。 feature分支：由于 develop 分支始终大于等于 master 的提交，当产品来了不同的需求后，分配了不同的任务给不同的人之后，每个人都可以根据develop 创建一个新的 feature 分支出来，我们所有的需求开发都在 feature 分支上进行， feature 开发完成后，都应合并回 develop，也就是说 develop 上保存的代码至少应该是开发者认为比较准确的，经过一定自测的代码。当 develop 上有一个或多个 feature 后，开发者即可部署 develop 到测试环境（这里就看出和我们先有的区别，我们有一个test分支，而 Git Flow 是没有 test 分支的），测试人员进行测试，期间如有任何的改动，都应该在各自的 feature 中开发并合并回 develop，继续进行测试。在测试期间，可能会有额外的 feature 产生， 若 develop 正在被进行测试， 那么此时产生的额外的 feature 不应该 合并回 develop， 直到 develop 测试稳定后，即产生下面这个分支。 release分支， 该分支是基于 develop 开发出来， 只要切出了这个分支，即代表 develop 可以被合并了。develop 的代码又可以 继续往前走了。 release 分支，也叫 发布分支， 发布分支会进行继续测试或预发部署等操作，若有相应修改，应该在该分支进行。而不是 develop。 等到完全稳定后，该分支应合并到 master 去。 合并后即可进行 打 tag 的操作。 之后如何利用 jenkins上线，是基于 master 还是 基于 tag 都看各自的使用。 hotfix分支：hotfix 分支 是线上的BUG分支， 必须是基于 master 开出来， 修改完后，创建PR，直接测试该分支，测试完成后，通过PR合并到 master。 以上的和分支一旦合并到 master 后，都应该让 develop 保持与 master 的同步。以确保下次基于develop切出来的是最新的代码。 以上即是一个完整的 Git workflow 的流程。 Feature Branch Flow: ​ 通过讲解上面的 Git Flow，对不同类型的分支已经有一个概念。而这里讲的 Feature Branch Flow 实际上就是一个简化版的 Git Flow（并不是先有GitFlow 再有 Feature Branch Flow）。该工作流正常只有 master 和 feature 分支，每次开发新需求，只需要从master分支切出一个新的出来，开发完并进行测试 feature 后，进行合并到 master， 该流程即完成。看起来比较简单，而实际上这也是一个现在流行的做法。 Forking Flow: ​ 这种工作流在上面介绍Fork的概念与使用场景的时候已经提到了。总的来说就是团队开发者对中央仓库进行Fork操作，派生到各自帐号下后，即可进行不同需求的开发，当开发完成后，即可进行创建PR的操作。但这种方式在团队协作中应用的比较少，该方式也不利于测试，说他流行是因为，开发者对开源社区进行贡献，均采用此种方式进行合并代码。 当前弊端： 上线之后，由于我们现在实行的是先合并代码到 master，并且只会拉取 master 的代码进行部署，一旦出问题，就无法快速切回上一个稳定版本。 当前的工作流有些类似 Feature Branch Flow，但也有区别，当前还未利用起来Issue与Pull Request，同时多了一个test分支， 反而在意义上看来， test 分支 更像是 Feature Branch Flow 的 develop 分支（某些Feature Branch Flow会有develop分支，但该分支同样不应该被直接修改代码），因为一旦涉及到多版本开发的时候，我们的要求是 不能再合并 test 到 master，而是合并 deve/ 到 master，这也和 Feature Branch Flow 理念一样。 考虑改进： 考虑在 Jenkins 部署的时候，可以对 tag 或 分支 进行选择，以此来进行快速的切换线上的代码，保证最小化影响。 团队可以利用起来 Issue 和 Pull request， 该方式是能切实保证团队代码质量与规范流程的一大助力。 开发，测试 可以多建立几套环境，以应对QA需要同时测试几个不同的需求。类似之前做过的 lf, lf_p, lf_back这些。但这些不免让人觉得不太好记，可以考虑使用以数字为后缀的名字，同时不再以 Git hook 来进行代码部署，直接使用 Jenkins， 给每套环境都准备好相应的 Job，并提供对 待测试分支进行选择的功能，这样在几个环境的加持下，即使来了演示需求，紧急修复，紧急需求，再配合Git工作流 都可以从容应对。 ","link":"https://hzqyihui.github.io/post/git-fen-zhi-yu-gong-zuo-liu/"},{"title":"netstat命令：查看端口占用","content":"netstat -tunlp 用于显示 tcp，udp 的端口和进程等相关情况。 netstat 查看端口占用语法格式： -t (tcp) 仅显示tcp相关选项 -u (udp)仅显示udp相关选项 -n 拒绝显示别名，能显示数字的全部转化为数字 -l 仅列出在Listen(监听)的服务状态 -p 显示建立相关链接的程序名 ","link":"https://hzqyihui.github.io/post/netstat-ming-ling-cha-kan-duan-kou-zhan-yong/"},{"title":"nl命令：带行号查看文件","content":"nl -b a 文件， 查看文件的时候， 空行也会 带行号 ，类似 cat -n nl -b t 文件， 查看文件的时候， 空行不带 行号， 也可写作 nl 文件 ","link":"https://hzqyihui.github.io/post/nl-ming-ling-dai-xing-hao-cha-kan-wen-jian/"},{"title":"Git奇难杂症：","content":" 在 Win 10 下，git bash 使用 git status 后， 中文是数字的。看起来很难受 ，使用 解决。 参考链接： http://xstarcd.github.io/wiki/shell/git_chinese.html 2. Linux 下， 每次 git status 都看到一大堆改变，实际上又没有文件内容的变化，原因在于， 文件的 权限发生了变化， 解决此问题，则忽略文件的权限变化。 ","link":"https://hzqyihui.github.io/post/git-qi-nan-za-zheng/"},{"title":"stat命令： 查看文件的修改","content":"stat命令： 查看文件的详细信息 为方便记忆， stat 可当做 status的缩写， 实际上就是查看文件的状态，也就是文件的详细信息。 使用 从图中看出， Access 代表最后一次的访问时间（仅是访问，不是修改） Modify 代表最后一次修改文件的时间 Change 代表最后一次修改文件属性的时间，如修改文件权限，文件大小等。 当我使用 cat 去查看文件的时候， Access Time 会跟着改变。 当我修改文件的时候，三个时间都会跟着改变， 当我修改文件的权限的时候， Change Time 会跟着改变， 如 chmod 777 从上面来看， 没法查到文件的创建时间， 有时候我想知道文件的创建时间， 这个时候就需要更细的去查看了。 文件的创建时间被存储在EXT4文件系统inode中。 EXT文件系统的早期版本不支持文件的创建时间。 有一个“ crtime “（创建时间）时间戳 debugfs统计输出。最后EXT4支持创建时间就像windows的 NTFS中的 “btime “一样。 按照以下如何找到文件的创建时间的说明。选择一个现有的文件或创建新的文件测试。在这个例子中，我使用现有的文件。 (只针对EXT4文件系统) 比如 ext4、xfs、btrfs 都支持，zfs、vfat、ntfs 不支持。 第1步：查找文件的inode编号 查找使用下面的命令终端的任何文件的inode号。 第2步：查找文件所在的分区或VG 从上面可以看出， /dev/mapper/developer--vg-root 被挂载 为 / ，create.txt 在 / 下面。 第3步：查找文件文件创建时间 输入以上命令后， 即可得到 具体的信息，如下所示： 上面结果中的 crtime 即为 该文件的创建时间。 ","link":"https://hzqyihui.github.io/post/stat-ming-ling-cha-kan-wen-jian-de-xiu-gai/"},{"title":"各类查找命令：","content":"各类查找命令： 1.1 find命令 Linux find 命令是所有 Linux 命令中最有用的一个，同时也是最混乱的一个。它很难，因为它的语法与其他 Linux 命令的标准语法不同。但是，它很强大，因为它允许您按文件名、文件类型、用户甚至是时间戳查找文件。使用 find 命令，您不但可以找到具这些属性任意组合的文件，还可以对它找到的文件执行操作。 1.2 locate命令 Linux locate命令用于查找符合条件的文档，他会去保存文档和目录名称的数据库内，查找合乎范本样式条件的文档或目录。locate 让使用者可以很快速的搜寻档案系统内是否有指定的档案。其方法是先建立一个包括系统内所有档案名称及路径的数据库，之后当寻找时就只需查询这个数据库，而不必实际深入档案系统之中了。在一般的 distribution 之中，数据库的建立都被放在 crontab 中自动执行。 1.3 grep命令 Linux grep命令用于查找文件里符合条件的字符串。grep也可以根据文件名查找文件，但一般用于查找文件内的内容。 grep（global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来）是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。 1.4 whereis命令 whereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。 1.5 which命令 which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 1.6 type命令 type命令其实不能算查找命令，它是用来区分某个命令到底是由shell自带的，还是由shell外部的独立二进制文件提供的。如果一个命令是外部命令，那么使用-p参数，会显示该命令的路径，相当于which命令。 1.7 总结 ","link":"https://hzqyihui.github.io/post/ge-lei-cha-zhao-ming-ling/"},{"title":"date命令：","content":"使用 date 可以直接查看当前日期。 若想要得到一个日期字符串所代表的秒数，则 举例如下： ","link":"https://hzqyihui.github.io/post/date-ming-ling/"},{"title":"find 命令：","content":"find 命令： 如： 参考： https://www.runoob.com/linux/linux-comm-find.html option的类型,expression 中可使用的选项有二三十个之多，在此只介绍最常用的部份。 根据文件内容来找文件： -exec 参数后面跟的是 command命令，注意点如下： command命令的终止，使用 ';' (分号）来判定，在后面必须有一个 ';' '{}'，使用{}来表示文件名，也就是find前面处理过程中过滤出来的文件，用于command命令进行处理 特别强调，对于不同的系统，直接使用分号可能会有不同的意义， 使用转义符 ''在分号前明确说明，对于前面我们遇到的问题，主要就是这个原因引起的！ ","link":"https://hzqyihui.github.io/post/find-ming-ling/"},{"title":"Linux进程，内存查看","content":"进程，内存查看 可用于查看某个进程的CPU，内存占用等 查看进程信息： 以上两种都对，但是输出的格式不同， 可以通过 man ps 命令来查看具体的解析细节。 查看进行运行的完整路径方法。 通过ps及top命令查看进程信息时，只能查到相对路径，查不到的进程的详细信息，如绝对路径等。这时，我们需要通过以下的方法来查看进程的详细信息： Linux系统使用的GNU ps命令支持3种不同类型的命令行参数 BSD 风格的参数，前面不加破折线 Unix 风格的参数，前面加单破折线 GNU 风格的长参数，前面加双破折线 STAT进程状态(第一个字符) R (Running): 该程序正在运行中 S (Sleep): 该程序目前正在睡眠状态 (idle), 但可以被唤醒(signal) D 不可被唤醒的睡眠状态 , 通常进程可能在等待 I/O 的情况 T 停止状态 (stop), 可能是在工作控制 ( 背景暂停 ) 或除错(traced) 状态 Z (Zombie): 僵尸状态 , 程序已经终止但却无法被移除至内存外 STAT进程状态(第二个字符) 1、 ps l 长格式输出 参数解释 2、 ps -ef 输出 参数解释 3、 ps -au(x) 输出 其代表含义如下：USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND ","link":"https://hzqyihui.github.io/post/linux-jin-cheng-nei-cun-cha-kan/"},{"title":"tree命令","content":"tree命令 默认情况下， Debian系列系统，都没有安装tree命令， 且无法通过 apt-get来安装 tree。 参数： 在项目目录下执行 go build 会生成可执行文件， 如果使用 go install 会，在GOPATH下的/bin目录下生成可执行文件（没有配置GOBIN）， 实际上就是比 go build 多执行了一个操作，移动可执行文件到 /bin目录 ","link":"https://hzqyihui.github.io/post/tree-ming-ling/"},{"title":"locate 命令：","content":"locate命令用于查找文件，它比find命令的搜索速度快，但是它需要一个数据库，这个数据库一般是 crontab 每天调用一次 updatedb 命令来更新的. 因此你只要执行 updatedb 这个命令就可以了, 当然这个命令操作的数据库需要root权限. ","link":"https://hzqyihui.github.io/post/locate-ming-ling/"},{"title":"Zsh 插件安装：","content":"Zsh 相关知识点： 插件 zsh-autosuggestion 可以进行命令建议， 也就是输入几个命令字母后，会有相应的建议命令隐藏在背后， 可以使用右键。补全命令。 安装自动建议插件： 安装高亮插件 最后再在 .zshrc 加入对应的插件名， 再 source .zshrc 启用 即可 具体位置在 .zshrc 文件中 plugins=(git) 位置处， 只需要间隔空格，加入就可以了 安装 自动跳转 之后在 .zshrc 中加入 以下行，再source .zshrc即可。 安装完成后，zsh 的变量会完全覆盖 原来 /etc/profile里的环境变量， 导致某些特殊的变量不能用。 问题 shell又bash变为zsh，发现/etc/profile中设置的环境变量全部失效了 在终端source /etc/profile设置的环境变量生效，但是zsh的主题以及插件消失。 在终端source ~/.zshrc后，zsh的主题和插件恢复 重新启动终端，环境变量再次失效 推测问题原因 /etc/profile的生效期是用户登录的时候，生效对象是所有用户的所有shell。然而最新安装的shell（zsh）不在/etc/profile的生效对象内。所以在变更shell时环境变量失效 在终端source /etc/profile时，重新载入了/etc/profile，所以环境变量生效，但是在/etc/profile中执行了 source /etc/bash.bashrc导致zsh的样式和主题失效（可以查看/etc/profile的源代码） 在终端source ~/.zshrc后，zsh的主题和插件恢复，理所当然样式和插件恢复 由于在终端中source /etc/profile只是让本shell进程执行，相当于只是在本shell执行了环境变量，所以重启之后依旧失效 尝试把变量直接加在.zshrc文件中 可以解决。 很多时候，我们会进入某个git项目目录中， zsh 会自动读取当前目录的git信息，并展示出来。这会造成卡顿，我们可去掉。 若需要恢复，则设置为0即可。 ","link":"https://hzqyihui.github.io/post/zsh-cha-jian-an-zhuang/"},{"title":"Linux系统基本知识点","content":"系统知识点： 1. 修改主机名： Ubuntu: 在 /etc/hostname 文件中即可修改 2. 添加环境变量 三种添加环境变量的方法： 1、直接使用export命令： 比如： 命令export可以查看各个系统变量和路径，发现系统变量中PATH中多了设置的路径，增加了CLASSPATH变量，则设置成功 也可单个变量输出查看： 2、 修改/etc/profile文件 在/etc/profile文件末尾添加： 有人说也可以在/etc/profile.d/文件夹中添加个sh文件，/etc/profile文件似乎会自动读取/etc/profile.d/文件夹中的各个脚本文件，我还没试过。 另外需要注意： CLASSPATH中当前目录“.”不能丢，把当前目录丢掉也是常见的致命错误。 在设置环境变量时特别要注意不能把原来的值给覆盖掉了，这是一种常见的错误。 软件越装越多，环境变量越添越多，为了避免造成混乱，所以建议所有语句都添加在文件结尾，按软件的安装顺序添加。 3、 修改主目录下的隐藏文件./bashrc 修改方式与修改/etc/profile文件相同 source .bashrc使修改生效 3.修改当前的shell 查看一共有多少shell 查看当前使用的shell 清楚DNS 缓存 参考： https://cnzhx.net/blog/how-to-flush-dns-cache-in-linux-windows-mac/ 若Linux上时间不对， 可用以下命令更新时间 需要区分 ntpd 和 ntpdate 5.1 ntpd 是一个时间服务，它会平滑的同步时间，有自己的机制去同步服务器时间 5.2 ntpdate 是直接更新时间，属于一个时间的跃变，这对业务会很有影响，在自己玩的虚拟机上，到是可以使用 ntpdate 直接更新，不然都建议使用 ntpd 平滑更新 安全Selinux： 禁止ping： 临时禁Ping： 永久禁ping IPTABLES防火墙禁ping ","link":"https://hzqyihui.github.io/post/linux-xi-tong-ji-ben-zhi-shi-dian/"},{"title":"Linux操作提升效率","content":"命令行： 生活在 Bash shell 中，熟记以下快捷键，将极大的提高你的命令行操作效率。 编辑命令 重新执行命令 控制命令 友情提示： ","link":"https://hzqyihui.github.io/post/linux-cao-zuo-ti-sheng-xiao-lu/"},{"title":"VIM学习笔记：","content":"可通过官方文档来学习 VIM学习： 2.1 一般安装vim后，不是完整版的，只是vim-tiny，也就是精简版的， 若需要完整版的，需要安装 2.2 为了让vim更方便人使用，可以进入vim的配置文件中修改一些配置： 之后在文件中加入以下配置： 2.3 分屏: :split 和 vsplit. 下面是主要的命令，你可以使用VIM的帮助 :help split. 你可以参考本站以前的一篇文章VIM分屏。 分屏启动Vim 分屏 2.4 复制命令： 2.5 剪切命令： 2.6 粘贴命令： 2.7 撤销和 反撤销 (undo redo) 2.8 vim纵向模式： 2.9 自动缩进当前行指令 == 格式化当前光标接下来的8行 8= 格式化选定的行 v 选中需要格式化的代码段 = 备注： 2.10 查找与替换 2.10.1 作用范围： 删除与复制 同理： 2.11 ESC键可以 被 ctrl + [ 或者 ctrl + c 替换，作用是一样的。都是退出编辑模式，进入命令模式 VIMRC vimrc是vim的 全局配置文件，目录在 /etc/vim/vimrc ， :%!xxd 可以查看当前文件的十六进制编码 中文键盘速查表： 在Vim内部执行shell命令 列模式编辑最后一列 使用列块模式 &lt;Ctrl + v&gt; （如果macvim或者gvim则是&lt;Ctrl + q&gt;）进入列块可视模式， jj$ 先下移动两行然后跳到行尾； A; 进入插入模式输入分号； 回到普通模式完成插入。 可参考：https://jelly.jd.com/article/6006b1045b6c6a01506c87ce ","link":"https://hzqyihui.github.io/post/vim-xue-xi-bi-ji/"},{"title":"crontab","content":"crontab 使用 cron的时候，我们经常会因为 某个命令运行时间太长，命令再次被启动时，会出现多进程。 可以使用flock, 如： 当多个进程可能会对同样的数据执行操作时，这些进程需要保证其它进程没有也在操作，以免损坏数据。 通常，这样的进程会使用一个「锁文件」，也就是建立一个文件来告诉别的进程自己在运行，如果检测到那个文件存在则认为有操作同样数据的进程在工作。这样的问题是，进程不小心意外死亡了，没有清理掉那个锁文件，那么只能由用户手动来清理了。 参数 实例 crontab运用flock防止重复执行 ","link":"https://hzqyihui.github.io/post/crontab/"},{"title":"环境变量etc profile文件解析：","content":"/etc/ profile文件解析：该文件对所有用户均有效 有时候我们在安装了一个软件之后，会得到一些可执行命令，可是这些可执行命令只在安装软件的目录下，我们要么直接使用绝对路径。要么就使用链接， 在/usr/local/bin 这些bin文件夹中，建立一个链接： ln -s /usr/local/go/bin /usr/local/bin 这样太复杂了 ，如果很多，都要建立，那就太费时间了， 于是我们需要了解 profile文件的作用。 Linux有个常量叫： PATH，直接输入执行后，得到当前系统，哪些路径是环境变量的路径：我们可以把新软件的Bin目录给加入进去：直接在/etc/profile文件最后一行加入：exportPATH=PATH，直接输入执行后，得到当前系统， 哪些路径是环境变量的路径： 我们可以把新软件的Bin目录给加入进去： 直接在/etc/profile文件最后一行加入： export PATH=PATH，直接输入执行后，得到当前系统，哪些路径是环境变量的路径：我们可以把新软件的Bin目录给加入进去：直接在/etc/profile文件最后一行加入：exportPATH=PATH:/usr/local/go/bin 这样的话， 新软件的bin目录直接就是环境变量路径了，直接可使用可执行命令了。 Linux环境变量PATH设置 参考资料： 博客峰子_仰望阳光的博文Linux中环境变量设置 博文/etc/profile文件详解 博文 Linux中profile、bashrc、bash_profile之间的区别和联系 相关背景 Linux是一个多用户的操作系统。每个用户登录系统后，都会有一个专用的运行环境。通常每个用户默认的环境都是相同的，这个默认环境实际上就是一组环境变量的定义。用户可以对自己的运行环境进行定制，其方法就是修改相应的系统环境变量。 相关文件介绍 /etc/profile:此文件为系统的每个用户设置环境信息，当用户第一次登录时，该文件被执行。在这里修改的内容是对所有用户起作用的。所以如果你有对/etc/profile有修改的话必须得重启系统，你的修改才会生效，此修改对每个用户都生效。 /etc/bashrc:为每一个运行 bash shell 的用户执行此文件。当 bash shell 被打开时，该文件被读取。如果你想对所有的使用bash的用户修改某个配置并在以后打开的bash都生效的话可以修改这个文件，修改这个文件不用重启，重新打开一个bash即可生效。 ~/.bash_profile: 每个用户都可使用该文件输入专用于自己使用的 shell 信息，当用户登录时，该文件仅仅执行一次。此文件类似于/etc/profile，也是需要需要重启才会生效，/etc/profile对所有用户生效，~/.bash_profile只对当前用户生效。 ~/.bashrc:该文件包含专用于你的bash shell的bash信息,当登录时以及每次打开新的shell时,该文件被读取.（每个用户都有一个.bashrc文件，在用户目录下，符号‘~’就表示用户目录） ~/.bash_logout:当每次退出系统(退出bash shell)时,执行该文件。 /etc/profile和/etc/bashrc都是系统级别的，修改后可以在所有用户中起作用；/.bash_profile、/.bashrc和~/.bash_logout都是用户级别的，修改后只会作用于当前用户。 带profile的文件都是需要重新进入用户时才会生效，带bashrc的则是打开新的shell时生效； 启动过程 执行顺序：/etc/profile -&gt; (~/.bash_profile | ~/.bash_login | ~/.profile) -&gt; ~/.bashrc -&gt; /etc/bashrc -&gt; ~/.bash_logout Linux环境变量相关命令 显示环境变量HOME $ echo HOME设置新的环境变量HELLOHOME 设置新的环境变量HELLO HOME设置新的环境变量HELLO export HELLO=&quot;Hello&quot; 显示所有环境变量 $ env 显示所有本地定义的Shell变量 ￥ set 清除环境变量 $ export TEST=&quot;test&quot; $ env|grep TEST #此时显示：TEST =test $ unset TESTTEST TEST env|grep TEST #此时已经没有显示了，说明没有对应的环境变量了 设置只读变量 readonly TEST 设置Linux环境变量 之前介绍的使用export命令设置环境变量是在命令行中直接执行，这样设置的环境变量在退出shell时就会失效。要想设置永久有效的环境变量就需要修改之前提到的文件。 PATH声明 PATH=$PATH:&lt;PATH 1&gt;:&lt;PATH 2&gt;:&lt;PATH 3&gt;:------: 你可以自己加上指定的路径，中间用冒号隔开 需要注意的是，最好不要把当前路径”./”放到PATH里，这样可能会受到意想不到的攻击。 举例：在/etc/profile文件中添加环境变量 特点：所有用户；永久有效；生效需要重新进入用户 root权限： vim /etc/profile export CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib 要想修改完文件后就立即生效，可以在命令行中执行： source /etc/profile Source命令也称为“点命令”，也就是一个点符号（.）。source命令通常用于重新执行刚修改的初始化文件，使之立即生效，而不必注销并重新登录 常用环境变量 PATH 决定了shell将到哪些目录中寻找命令或程序 HOME 当前用户主目录 HISTSIZE 历史记录数 LOGNAME 当前用户的登录名 HOSTNAME 指主机的名称 SHELL 当前用户Shell类型 LANGUGE 语言相关的环境变量，多语言可以修改此环境变量 MAIL 当前用户的邮件存放目录 PS1 基本提示符，对于root用户是#，对于普通用户是$ 解决在/etc/porfile下设置环境变量以后zsh没有起效的问题 问题１： 今天在添加java的环境变量的时候，我在/etc/profile添加了环境变量，因为我使用的是zsh，在source /etc/profile以后，zsh的主题和插件都没有了，java -version以后出现旗标信息，以为可以了，但是没有主题就很难受，重启shell。java -version提示没有此命令，懵~ 推测问题原因: 由于在终端中source /etc/profile只是让本shell进程执行，相当于只是在本shell执行了环境变量，所以重启之后依旧失效 推测解决方法: 在~/.zshrc中添加source /etc/profile 重启shell 输入java -version 完美解决! 通过百度发现:zsh其实并不使用/etc/profile文件，而是使用/etc/zsh/下面的zshenv、zprofile、zshrc、zlogin文件，并以这个顺序进行加载。 所以推测还有一种方法，在/etc/zsh/zprofile下面export相应的环境变量. 问题２： 在后面的使用中，发现切换到root用户的时候，java的环境变量又不生效了。 解决办法: 在/root/.bashrc文件尾部添加： source /etc/profile ok，完美解决 ","link":"https://hzqyihui.github.io/post/huan-jing-bian-liang-etc-profile-wen-jian-jie-xi/"},{"title":"Linux etc sudoers文件说明：","content":"/etc/sudoers文件说明： 简介 sudo是linux下常用的允许普通用户使用超级用户权限的工具，允许系统管理员让普通用户执行一些或者全部的root命令，如 halt，reboot，su等等。这样不仅减少了root用户的登陆 和管理时间，同样也提高了安全性。Sudo不是对shell的一个代替，它是面向每个命令的。它的特性主要有这样几点： 2.简单解析： 一般来说，通过cat /etc/sudoers指令来查看该文件, 会看到如下几行代码: 对/etc/sudoers文件进行编辑的代码公式可以概括为: 为了方便说明, 将公式的各个部分称呼为字段1 - 字段5: 在上面的默认例子中, &quot;字段1&quot;不以%号开头的表示&quot;将要授权的用户&quot;, 比如例子中的root； 代表：表示: 普通用户 max 在主机(或主机组)mycomputer上, 可以通过sudo执行reboot和shutdown两个命令。&quot;字段3&quot;和&quot;字段4&quot;省略。 &quot;字段3&quot;如果省略, 相当于(root:root)，表示可以通过sudo提权到root; 如果为(ALL)或者(ALL:ALL), 表示能够提权到(任意用户:任意用户组)。 请注意，&quot;字段3&quot;如果没省略,必须使用( )双括号包含起来。这样才能区分是省略了&quot;字段3&quot;还是省略了&quot;字段4&quot;。 &quot;字段4&quot;的可能取值是NOPASSWD:。请注意NOPASSWD后面带有冒号:。表示执行sudo时可以不需要输入密码。比如: 表示: 普通用户 max 可以在任何主机上, 通过sudo执行/bin/useradd命令, 并且不需要输入密码. 又比如: 表示: 普通用户 peter 可以在任何主机上, 通过sudo执行任何命令, 并且不需要输入密码。 &quot;字段5&quot;是使用逗号分开一系列命令,这些命令就是授权给用户的操作; ALL表示允许所有操作。 你可能已经注意到了, 命令都是使用绝对路径, 这是为了避免目录下有同名命令被执行，从而造成安全隐患。 如果你将授权写成如下安全性欠妥的格式: 那么用户就有可能创建一个他自己的程序, 也命名为userad, 然后放在它的本地路径中, 如此一来他就能够使用root来执行这个&quot;名为useradd的程序&quot;。这是相当危险的! 命令的绝对路径可通过which指令查看到: 比如which useradd可以查看到命令useradd的绝对路径: /usr/sbin/useradd 公式还要扩充 例子1: 表示: 用户papi能在所有可能出现的主机上, 提权到root下执行/bin/chown, 不必输入密码; 但运行/usr/sbin/useradd 命令时需要密码. 这是因为NOPASSWD:只影响了其后的第一个命令: 命令1. 上面给出的公式只是简化版，完整的公式如下: 在具有sudo操作的用户下, 执行sudo -l可以查看到该用户被允许和被禁止运行的命令. 通配符和取消命令 例子2: 用例子2来说明通配符*的用法, 以及命令前面加上!号表示取消该命令。 该例子的意思是: 用户papi在所有可能出现的主机上, 能够运行目录/usr/sbin和/sbin下所有的程序, 但fdisk除外. 开始编辑 “你讲了这么多,但是在实践中,我去编辑/etc/sudoers文件，系统提示我没权限啊，怎么办?” 这是因为/etc/sudoers的内容如此敏感，以至于该文件是只读的。所以，编辑该文件前，请确认清楚你知道自己正在做什么。 强烈建议通过visudo命令来修改该文件，通过visudo修改，如果配置出错，会有提示。 不过，系统文档推荐的做法，不是直接修改/etc/sudoers文件，而是将修改写在/etc/sudoers.d/目录下的文件中。 如果使用这种方式修改sudoers，需要在/etc/sudoers文件的最后行，加上#includedir /etc/sudoers.d一行(默认已有): 注意了，这里的指令#includedir是一个整体, 前面的#号不能丢，并非注释，也不能在#号后有空格。 任何在/etc/sudoers.d/目录下，不以~号结尾的文件和不包含.号的文件，都会被解析成/etc/sudoers的内容。 文档中是这么说的: 其他小知识 输入密码时有反馈 当使用sudo后输入密码，并不会显示任何东西 —— 甚至连常规的星号都没有。有个办法可以解决该问题。 打开/etc/sudoers文件找到下述一行: 修改成: 修改sudo会话时间 如果你经常使用sudo 命令，你肯定注意到过当你成功输入一次密码后，可以不用再输入密码就可以运行几次sudo命令。 但是一段时间后，sudo 命令会再次要求你输入密码。默认是15分钟，该时间可以调整。添加timestamp_timeout=分钟数即可。 时间以分钟为单位，-1表示永不过期，但强烈不推荐。 比如我希望将时间延长到1小时，还是打开/etc/sudoers文件找到下述一行: 修改成: 参考URL：https://segmentfault.com/a/1190000007394449 ","link":"https://hzqyihui.github.io/post/linux-etc-sudoers-wen-jian-shuo-ming/"},{"title":"Linux 用户，用户组相关命令","content":"用户，用户组相关： 对某个命令，不懂，可以直接使用 命令 --help 来查看帮助信息，如： ·useradd --help· 添加用户： 之后修改密码： 如果只是上面的命令，最后通过用户名和密码登录了系统，会发现该用户登录后， 用户名，主机名的位置，只有一个$符号， 而且按退格键，也不行，这就代表着没有给该用户指定shell，用户不能正常使用。 可通过： 或者直接在添加用户的时候，直接指定： 可以显式的指定某个shell， 同样也可以使用默认配置， 在 可以显式的指定某个shell， 同样也可以使用默认配置， 在 该配置只适用于 adduser 命令， adduser 不同于 useradd， 前者类似一个命令集合，一个shell脚本，会帮你配置，路径，shell，提示你输入密码这些的。而 useradd 是一个基础命令。 ","link":"https://hzqyihui.github.io/post/linux-yong-hu-yong-hu-zu-xiang-guan-ming-ling/"},{"title":"ln命令：对文件做链接，类似Windows的快捷方式","content":"ln命令： 对文件做链接，类似Windows的快捷方式 在很多情况下都会用到 ln 命令，作用在于基于原来的文件，创建一个链接，无论是软链接还是硬链接。 语法： 1.1 软链接：创建一个源文件的镜像，不占用空间，且随着源文件变动而变动。 该命令，必须把源文件和目标文件都写上具体的路径名字，不能写相对路径。 1.2 硬链接：创建一个源文件一模一样的文件，占用空间，且随着源文件变动而变动。 该命令，必须把源文件和目标文件都写上具体的路径名字，不能写相对路径。 ","link":"https://hzqyihui.github.io/post/ln-ming-ling-dui-wen-jian-zuo-lian-jie-lei-si-windows-de-kuai-jie-fang-shi/"},{"title":"df","content":"df: //查看系统中文件的使用情况 //查看当前目录下各个文件及目录占用空间大小 ","link":"https://hzqyihui.github.io/post/df/"},{"title":"chmod：","content":"chmod： 1.将文件 file1.txt 设为所有人皆可读取 : 2.将文件 file1.txt 设为所有人皆可读取 : 3.将文件 file1.txt 与 file2.txt 设为该文件拥有者，与其所属同一个群体者可写入，但其他以外的人则不可写入 : 4.将 ex1.py 设定为只有该文件拥有者可以执行 : chmod -R a+r * 改变用户组： chown -R Administrator:Administrator file chmod 777 file chmod abc file 其中a,b,c各为一个数字，分别表示User、Group、及Other的权限。 r=4，w=2，x=1 若要rwx属性则4+2+1=7； 若要rw-属性则4+2=6； 若要r-x属性则4+1=5。 chmod a=rwx file 和 chmod 777 file 效果相同 chmod ug=rwx,o=x file 和 chmod 771 file ","link":"https://hzqyihui.github.io/post/chmod/"},{"title":"tar命令：","content":"tar命令： 常见解压/压缩命令 tar （注：tar是打包，不是压缩！） .gz .tar.gz 和 .tgz .bz2 .tar.bz2 .bz .tar.bz ","link":"https://hzqyihui.github.io/post/tar-ming-ling/"},{"title":"GIT 原理   ：","content":"Git 是一套内容寻址文件系统。很不错。不过这是什么意思呢？ 这种说法的意思是，Git 从核心上来看不过是简单地存储键值对（key-value）。它允许插入任意类型的内容，并会返回一个键值，通过该键值可以在任何时候再取出该内容。 我们都知道当我们初始化一个仓库的时候，也就是执行以下命令后，文件夹内会生成一个.git文件夹， 内部会包含，以下文件夹。 hooks //钩子文件夹，内部文件实际上就是一些特定时间触发的shell脚本，我们可以简单的做一个部署系统，每次提交特定tag的时候，则部署最新的代码到服务器。 objects //真正的内容存放的文件夹，下面重点讲下这里。 refs //refs目录存放了各个分支（包括各个远端和本地的HEAD）所指向的commit对象的指针（引用），也就是对应的sha-1值；同时还包括stash的最新sha-1值 config //git配置信息，包括用户名，email，remote repository的地址，本地branch和remote branch的follow关系 HEAD //存放的是一个具体的路径，也就是refs文件夹下的某个具体分支。意义：指向当前的工作分支。项目中的HEAD 是指向当前 commit 的引用，它具有唯一性，每个仓库中只有一个 HEAD。在每次提交时它都会自动向前移动到最新 的 commit index //存放的索引文件，可使用 git ls-files --stage 查看。应该zlib加密后的，PHP可使用gzdeflate()函数 这是objects文件夹，可以看到都是些数字和字符，实际上就是十六进制数。 下图是进入00文件夹后所有文件。 认识下GIT对象： blob对象， tree对象， commit对象 1.创建blob对象 下面我们直接上底层命令， 运行此命令后，会在 .git/objects 文件夹下生成一个 两个字符 的文件夹，文件夹内部文件即类似上图中文件一样。 分解命令： 所以实际上我们看到的，objects 文件夹下的内容，文件名实际上是 hash 值。文件夹是40个字符的前两个（拥有相同前2位的hash值会被分配到同一个文件夹中）， 具体文件名则是后面38个字符。使用hash值的原因就在于，位数够多，并且hash值唯一，一点小变化，都会生成新的hash值，和md5算法是一样的道理。 注意：此hash值就像是GIT的指针，能唯一对应某一个具体的内容或提交，hash值作为寻址作用，不作为内容存储用，具体的文件内容存储方式是GIT更底层的存储方式决定。（sha-1和md5一样，均是不可逆的） 通过Linux find 命令查看所有已存储的hash文件： 通过 cat-file 命令可以将数据内容取回。该命令是查看 Git 对象的瑞士军刀。传入 -p 参数可以让该命令输出数据内容的类型： 通过 hash-object 命令，会把每一个文件的内容都给记录下来， 以此生成一个blob对象。可通过以下命令查看对象的类型 在实际项目过程中，不会这么简单，因为我们每次提交都是一个多文件的提交。很少的时候是单文件的，那此时Git就不是单单存储一个 blob对象了，而是 tree对象， tree对象，见名知意，就是一个树对象，类似于操作系统目录，tree的分支，可能还是tree，也可能是blob，这就看实际的场景了。 对象存储方法： GIT使用 zlib 库 的 deflate方法对数据内容进行压缩，但内容为 &quot;blob 字符串长度+空字节+字符串本身&quot;； 如： 2.创建tree对象 上面说的创建blob对象，仅仅只是对某一个文件进行的计算与存储，而我们实际项目中，可能每一次操作都是好几个，甚至十几个文件一起，那如何才能把他们组织到一起，这就是 tree 对象的作用了。 要创建tree对象，需要使用 update-index，write-tree 命令： --cacheinfo 会从已存在的数据库（Object）中取得对应的内容给添加到索引中。 实际生产中，一般情况下，会把末尾文件夹中的所有修改文件创建，blob对象，再对该文件夹（也就是所有的blob对象整体）进行write-tree的操作，得到一个tree对象，反复进行此操作，最后得到多个tree对象和多个blob对象。 如上所说，若需要对某个存在三级文件夹的二级文件夹进行write-tree操作， 在把三级文件夹下的所有修改文件生成blob后，进行整体tree对象化，之后再与二级文件夹同级的文件夹和文件进行相同操作。此时就需要用到： read-tree 命令。如： 3.创建commit对象 平时我们都是用** git commit -m &quot;xxxx&quot;** 提交了信息， 在这之前，会暂存相关文件的改动， 在提交后，会生成对应的tree对象，返回tree所对应的 sha-1值， 再进行一次 commit-tree 操作，最后会把刚保存的tree对象所对应的sha-1值 赋值给 commit-tree， 即生成了一个commit 对象。用法： 通过 git cat-file -p f7bc39001ff6cb183022234c94aa61ddedee44e0 得到： 我们还可以给某一个commit对象指定它的父commit对象： 通过 git cat-file -p 42e08b70c341b7e60944de6dffc342b77f94f6e4得到： 想要查看我们使用管道命令生成的log记录： git log --stat 42e08b70c341b7e60944de6dffc342b77f94f6e4 ,得到： 从上面的用法可以得到， git commit-tree 生成的 commit对象，只会包含 tree对象，参数选项中没有可以指定blob对象的参数。 如下：在测试时，强制使用blob对象的 sha-1值，会出现报错现象。 4.应用 以上基本上就可概括平时使用git add 和 git commit 命令时GIT的工作。 保存已修改文件成blob格式对象： git hash-object -w 各个文件 更新索引： git update-index --add 各个文件名 或者 git update-index --add --cacheinfo mode sha-1 文件名 或者 git read-tree --prefix=test sha-1(某个tree的sha-1) ，作用在于把某个tree读入索引中 创建树对象: git write-tree 最后创建commit对象： git commit-tree sha-1 -m &quot;提交信息&quot; 或者 echo &quot;提交信息&quot; | git commit-tree sha-1 -p 父级sha-1 4.1 git add 平时我们在使用的时候，使用 git add c.txt 后，把 c.txt 放入了暂存区， 而实际上此时已经生成了blob对象，并保存了相应的sha-1值命名的文件，同时添加到了索引文件中；之后当我们修改了之前添加到暂存区的文件并使用 git status 查看状态的时候，GIT会再对文件进行一次 hash运算，如果发现和已存在与索引中的内容产生了变化（sha-1值不同），则又会呈现出一个 Modify 状态。 通过以下命令可查看到 .git/index 文件中的内容，其中存放了每一个被追踪的文件，对应的blob对象最新的sha-1值， 通过这里即可很直接的判断出哪个文件是否被修改，哪些没有被追踪了。 4.2 git diff 同上， 使用 git diff后， 会把文件的差异给列出来，而对比对象即是 索引中的内容，并不是HEAD指向的内容。 当对某文件执行了 git add 后，之后再进行修改，再使用git diff 查看区别， 你会发现已经存在区别了。也就是说，git diff 实际上是把当前文件与索引中的文件进行比较（通过sha-1值比较），当有不同的情况，则列出对应的改变。 4.3 git status 使用 git status 后，GIT会对所有文件进行sha-1值计算，若计算到与前面讲到的 索引中得对应文件的sha-1值不同了，则代表有所改动，则标记为 Modify，若发现索引中不存在对应文件的sha-1值， 则标记为 Untracked files。 4.4 git branch 分支名 该命令会生成一个新分支，也就是在 .git/refs/heads里面生成一个新的文件，文件名为分支名，如果有前缀feature之类的。则feature是文件夹名，其内是文件名。文件内容为当前的 commit 对象对应的sha-1值。所以实际上分支，也是一个 commit 对象的引用。只是在GIT中专门有文件记录了分支名和指向。我们甚至可以通过创建文件的方式，直接创建branch。 4.5 git checkout 某分支 当使用 git checkout 的时候， GIT内部实际上就是把当前的HEAD指针给指向了另一个分支，而实际上也就是把 .git/HEAD 文件内容修改为切换的分支，而 .git/HEAD 内容指向的就是 .git/refs/heads中的分支，此文件内容又是一个 commit 对象的 sha-1值，所以也就间接指向了某个具体的 commit对象了， 从这个commit对象可得到它的父级对象，依次类推，即可得到完整的代码。 有时候，我们在使用PHPStorm的时候，会用到&quot;Annotate&quot;， 就是查看本文件的GIT提交记录，还会查看某个提交下以前的版本的文件，看具体是修改了啥。&quot;Amnotate previous revision&quot;，实际上就是做了 4.6 git commit -m &quot;提交信息&quot; 见如上信息。 4.7 git log 使用该命令后，去 .git/logs 下寻找当前分支对应的文件名，文件中的内容即为每一次提交的信息。 4.8 git push 使用git push 是把当前的分支上传到远程仓库，并把这个 branch 的路径上的所有 commits 也一并上传。 我认为实际就是修改了.git中的文件，因为这些文件里实际上就已经包含了压缩后的代码，等你切换分支的时候，GIT会根据这些内容把代码给检索出来。 4.9 git tag [version name] 使用 git tag 实际上和 git branch 类似，branch 是指向某一个commit的指针，但是branch会随着每次提交而移动， 但是tag不会， 当打了tag后， 那这个 tag 对应的commit对象指针就固定了，不会移动了。它和 git branch 一样，都不会产生blob或 tree 对象， git tag 只会在 .git/refs/tag 下生成一个 tag名的文件，内容为指向当前commit的sha-1 4.10 git stash 使用git stash 实际上是创建了一个新的commit对象，为什么这么说呢？在 .git/refs 目录下，当第一次stash后，会生成一个 stash文件， 内容即为一个sha-1值， 通过 git cat-file -p查看到具体内容为一个 commit对象的内容， 还能看到其有两个 父级 commit， 一个是前一个 git commit 的sha-1值， 一个是执行stash后，新生成的commit。最后把这两个commit对象作为父亲，再生成一个commit对象存放于stash文件中。 疑问： git commit-tree的时候，是怎么指定父级commit对象的，以什么为参考，才能指定对应的父级commit对象。我从平时工单的log记录来看，有些commit对象有两个父级commit对象（可能是合并操作的时候自动生成的commit对象），但不一定就是前一个commit。(git stash 有两个父级对象) 我们都知道git stash 存的是一个栈的结构，但是 .git/refs/stash 文件里 只有一个sha-1值，只对应一个commit对象，我查看了commit对象的具体内容，他的两个父亲均不是我前一个创建的stash对应的commit对象，不知道这个栈的结构怎么来的。 看某项目的树结构，会发现，每一个commit对象内部对应的 tree，都是一整个项目，而不是某一个文件或者某几个文件夹，这就解决了我的疑惑， 每次只需 git update-index --add 后，我想新创建一个 tree对象， tree对象内部一直会存在之前加入index中的blob对象。 那么GIT实际上就是每一个commit，都应该能从tree和 p-tree上追溯到整个项目文件。 在手动创建分支的过程中，发现在执行 git init后，看起来你是在master分支， 但是实际执行 git branch，看不到任何输出，这说明在这个时候实际上master分支是没有创建的，必须要有第一次提交后，master分支才会创建，因为只有这样 ， .git/refs/head/master 文件中才有可写的 commit 对象的 sha-1值。 需要注意：对commit对象的跟踪，commit对象能跟踪到具体哪一次修改，改了哪些具体文件，通过对commit的切换，就能找到某个时间点的文件记录了。GIT每次提交文件，实际上都是提交的整个文件，而不仅仅是修改的部分。所以当我们执行一些回退操作的时候能回到某个时间点的文件，即直接指定某个commit对象，查到commit对象中包含的各类tree对象和blob对象，把这些对象中压缩内容给取出来覆盖当前的同级，同名文件即可；同时新增的，给删除了。 ","link":"https://hzqyihui.github.io/post/git-yuan-li/"},{"title":"tmux使用","content":"tmux 工具使用： 新建会话 下面我们就来新建一个会话。可以使用 new 命令新建会话，并且该命令允许以参数的形式传递一个会话名。我的建议是在新建时要提供一个会话名以便于日后管理。(-s 可以想成 server，意思是新建一个server) 新建会话但并不指定名字 (不推荐这样做) 接入一个之前的会话 既然我们已经创建了多个带有名称的会话，那么就可以随时接入了，有几种方法可以实现接入会话： 可以简单地输入 tmux a 命令，这样可以接入第一个可用的会话：（a 可以 当成是 access(接入，进入)的缩写） 或者可以通过参数指定一个想接入的会话： 从会话中断开 可以使用 detach 命令断开已有的会话（因此才会有稍后重新接入会话这么一说）。 也可以使用快捷键断开会话： 关闭会话 要关闭会话的话，可以使用如下的命令，该命令和接入会话时所使用的命令很像： 提示：关闭窗口时也可以使用类似的命令，只不过要把 kill-session 换成 kill-window。另外，还可以使用 tmux killall 同时关闭 tmux。 从零开始编译自己的Linux：网址： https://linuxstory.org/linux-from-scratch-8-0-released/ 学习tmux 网址； https://www.jianshu.com/p/fd3bbdba9dc9 http://mingxinglai.com/cn/2012/09/tmux/ ","link":"https://hzqyihui.github.io/post/tmux-shi-yong/"},{"title":"Debian9学习笔记：","content":"Debian9学习笔记： 安装命令笔记： http://man.linuxde.net/yum 第一次安装Debian：需要做的事： SSH设置可登录，在/etc/ssh文件夹下， 把sshd_config文件的 PermitRootLogin 一行，改为 PermitRootLogin yes， 再 service ssh restart重启服务，即可使用账户密码登录。 由于使用的虚拟机，可在VirtualBox中设置端口转发， 如本机127.0.0.1的22222端口对应虚拟机内部10.0.2.15的22端口，即可正常连接。 由于新安装的Debian很多命令不能用，需要更新/etc/apt/source.list中的源。 阿里云源： Debian 镜像 简介 Debian GNU/Linux ，是一个操作系统及自由软件的发行版，由一群自愿付出时间和精力的用户来维护并更新。它附带了超过 59000 个软件包，这些预先编译好的软件被打包成一种良好的格式以便于用户安装和使用。 下载地址: https://mirrors.aliyun.com/debian/ https://mirrors.aliyun.com/debian-archive/ 配置方法 debian 7.x (wheezy) 编辑/etc/apt/sources.list文件(需要使用sudo), 在文件最前面添加以下条目(操作前请做好相应备份) debian 8.x (jessie) 编辑/etc/apt/sources.list文件(需要使用sudo), 在文件最前面添加以下条目(操作前请做好相应备份) debian 9.x (stretch) 编辑/etc/apt/sources.list文件(需要使用sudo), 在文件最前面添加以下条目(操作前请做好相应备份) debian 10.x (buster) 编辑/etc/apt/sources.list文件(需要使用sudo), 在文件最前面添加以下条目(操作前请做好相应备份) debian 11.x (bullseye) 编辑/etc/apt/sources.list文件(需要使用sudo), 在文件最前面添加以下条目(操作前请做好相应备份) 由于新安装的debian，导致很多命令都没有，则可以直接安装，apt-get install vim，apt-get install ifconfig 若使用非root用户，去安装vim之类的工具会提示权限不足，导致不允许，则可以去加入sudoers.is not in the sudoers file 在此之前可能压根就不存在这个文件，这个时候就需要去安装 sudo 才可用。apt-get install sudo 此时可以把当前用户加入到sudoers组里去，则可以 直接 去编辑 /etc/sudoers 文件， 加入：root ALL=(ALL:ALL) ALL 这种类似的 ，替换用户名保存即可，非root用户使用sudo 接下来就可以正式进入安装Docker的环节了。 由于是在VirtualBox中安装的debian， 故需要添加一些额外的增强功能 6.1 首先，在某个虚拟机实例的设置中，添加控制器， VirtualBox Guest Additions.iso， 在这里挂载了后，就进入Debian中。执行： 后面的是想要挂载的目录 6.2， 挂载后，进入到 home/max/www/ 目录中， 执行： 之后就可以重启虚拟机，可正常执行挂载共享文件夹了。 若一开始选择的中文语言，希望后期能改到英文去，可进行： 将下面两行内容 然后重启系统，显示正常了。 若需要定制一些命令的别名（此方法适合对该用户永久生效），可以在自己的家目录创建.bash_aliases文件。 有个工具zsh很好用，比原始的sh和bash 要好用，故提供安装： 安装好后，更换本机的shell，使用： 在安装了zsh后， 给用户指定shell的过程中， 因为直接输入的， //这样也能把zsh 写入到 /etc/passwd文件中，但是当时遇到个问题，当想使用该用户登录的时候，无论怎么样操作，都登录不上，用户名，密码都是对的。 后面发现就是因为在换 shell的过程中， 换错了。 zsh必须指定绝对路径，不然就会导致登录不进去。 可参考： https://mengkang.net/153.html 更换后，重新登录终端即可。虽然zsh比较好用，但是zsh还有更好用的主题，最出名的就是oh-my-zsh 安装完成后，可以更改默认的zsh主题，再 可能存在下不下来的 情况，此时需要把install.sh 在本地进入打开后， 把内容粘贴到 linux 中，再手动执行， 又可能存在 Git 报错，又被墙了，此时 设置 不使用代理。 显示本机ip， 导入某个命令到环境变量中去： github520 帮助随时能访问 github 问题： 在下载某些依赖或者安装包后发现终端乱序，输入命令时按退格键不能回退反而向后加空格；并且某些快捷键无法使用等问题； 原因 终端依赖的包ncurses-base被删除； 解决办法 终端输入： ","link":"https://hzqyihui.github.io/post/debian9-xue-xi-bi-ji/"},{"title":"Docker学习笔记","content":"Docker学习笔记： docker中文网： https://docs.docker-cn.com/ 检查docker的版本命令： 查看docker更多细节信息的命令： 查看本机所有docker镜像 查看本机所有docker容器 获取docker帮助 6.删除docker镜像 列出本机正在运行的容器： 8.运行容器 此命令，每次运行都会生成一个容器，可用在第一次依赖镜像创建容器的时候，因为该命令会配置一些参数，生成的容器即带了所配置的参数了。 创建后，以后要运行，直接可以通过容器ID来运行了，参考下面的命令。 开启已有的容器 终止已运行的容器 由于官方原镜像很慢，所以若需要更快的速度可以拉取docker镜像，则可以： 12.docker实用命令集合： mysql 测试： Dockerfile编写：学习链接 使用Docker Commit创建镜像 14.1 首先需要进入某个容器内， Docker网络： Docker容器有5种网络模式， 在使用docker run创建docker容器时，可以用--net选项指定容器的网络模式，Docker有以下5种网络模式： bridge模式 使用docker run --net=bridge指定，bridge模式是Docker默认的网络设置，此模式会为每一个容器分配Network Namespace、设置IP等，并将一个主机上的Docker容器连接到一个虚拟网桥上。 此模式与外界通信使用NAT协议，增加了通讯的复杂性，在复杂场景下使用会有诸多限制。 route -n 查看 IP routing tables; iptables -t nat -L -n 查看iptables rules. host模式 使用docker run --net=host指定，这种模式Docker Server将不为Docker容器创建网络协议栈，即不会创建独立的network namespace,Docker容器中的进程处于宿主机的网络环境中，相当于Docker容器的宿主机共用同一个network namespace,使用宿主机的网卡、IP、端口等信息。此模式没有网络隔离性，同时会引起网络资源的竞争与冲突。 container模式 使用docker run --net=container:othercontainer_name指定，这种模式与host模式相似，指定新创建的容器和已经存在的某个容器共享同一个network namespace, 以下两种模式都共享network namespace,区别就在于host模与宿主机共享，而container模式与某个存在的容器共享。 在container模式下，两个容器的进程可以通过lo回环网络设备通讯，增加了容器间通讯的便利性和效率。container模式的应用场景就在于可以将一个应用的多个组件放在不同的容器趾，这些 容器配成container模式的网络，这样它们可以作为一个整体对外提供服务。同时，这种模式也降低了容器间的隔离性。 docker run -it --name helloworld busybox sh docker run -it --name helloword-con --net=container:helloword busybox sh 4.none模式 使用docker run --net=none指定，在这种模式下，Docker容器拥有自己的Network Namespace，但是，并不为Docker容器进行任何网络配置。也就是说，这个Docker容器没有网卡、IP、路由等信息。需要我们自己为Docker容器添加网卡、配置IP等。这种模式如果不进行特定的配置是无法正常使用的，但它也给了用户最大的自由度来自定义容器的网络环境。 overlay模式 overlay网络特点： 跨主机通讯 无需做端口映射 无需担心IP冲突 服务发现与k/v存储: etcd, consul config1.sh This transaction has been declined 返回有关网络的信息： docker-compose up 与 docker run不同， docker-compose up不会新创建容器，除非手动删除容器，不然container id每次都相同，不同于docker run 每次都要根据镜像重新生成一个实例。 docker-compose.yml的写法 docker save ： 将置顶镜像保存成tar归档文件。 docker 镜像导入导出有两种方法： 一种是使用 save 和 load 命令 使用例子如下： 一种是使用 export 和 import 命令 使用例子如下： export 和 import 导出的是一个容器的快照, 不是镜像本身, 也就是说没有 layer。 你的 dockerfile 里的 workdir, entrypoint 之类的所有东西都会丢失，commit 过的话也会丢失。 快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也更大。 如果需要对已经生成的一个容器进行修改启动策略，可以使用 update 命令。 ","link":"https://hzqyihui.github.io/post/docker-xue-xi-bi-ji/"},{"title":"在Debian9安装Docker","content":"Docker： 镜像（Image）； 容器（Container）； 仓库（Repository）。 Debian系统，根据Docker官方教程来部署Docker 1.第一步： 去掉老旧版本的Docker， 若明确，系统内没有docker相关程序，也可不执行。 2.第二步：确保Linux内核大于 3.10 ，如何查看Linux内核，可用如下命令 若内核小于 3. 10 ，则可以升级内核，如需升级内核，可跳转：https://wiki.debian.org/HowToUpgradeKernel 3.第三步： 启用backports仓库，一般情况下首次安装完Debian后，source.list文件内的源都不够完整，推荐使用，中科大的源： 直接去 /etc/apt/source.list文件，粘贴以上内容，随后执行 由于我使用但是Debian9， 根据Docker官方描述：需要使用， Add Docker’s official GPG key: 此处可能会报错： 在网上查询：用此命令解决： 下面添加Docker仓库源 下面开始正式安装：（可根据第8 和 第9选择安装某个版本） 查找并列出docker-ce有哪些版本 接下来根据上面的结果选择安装的版本就好了。如：docker-ce=18.03.0.ce 安装完成查看安装的docker是否可用。 改名了会自动拉取 hello-world镜像，如果能显示正常的结果，则证明安装好了。接下来就是使用docker了。 建立docker开机启动 开启docker 13.默认情况下，docker 命令会使用Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使 用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。 建立docker组： 所有的安装完成后，可以再安装docker-compose: docker-compose的作用是，将所有需要共同关联的服务绑定到一起，可以直接一起启动，也就是一键启动。无需自己再一个个去启动各个容器了。 你需要定义一个 YAML 格式的配置文件docker-compose.yml，写好多个容器之间的调用关系。 安装web所需各类镜像 可参考的文档地址 ： https://yeasy.gitbook.io/docker_practice/install/centos 17： 安装 Mysql5.7 Ubuntu 16.04+、Debian 8+、CentOS 7+ 目前主流 Linux 发行版均已使用 systemd 进行服务管理，这里介绍如何在使用 systemd 的 Linux 发行版中配置镜像加速器。 请首先执行以下命令，查看是否在 docker.service 文件中配置过镜像地址。 如果该命令有输出，那么请执行 $ systemctl cat docker 查看 ExecStart= 出现的位置，修改对应的文件内容去掉 --registry-mirror 参数及其值，并按接下来的步骤进行配置。 如果以上命令没有任何输出，那么就可以在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件）： 注意，一定要保证该文件符合 json 规范，否则 Docker 将不能启动。 之后重新启动服务。 或者直接使用docker的官方shell，直接安装 ","link":"https://hzqyihui.github.io/post/zai-debian9-an-zhuang-docker/"},{"title":"Git学习笔记","content":"可供学习的链接： 内部原理： 可学习： 本地仓库(版本库) 版本库：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。 本地仓库(版本库)是什么 什么是版本库呢？版本库又名仓库，英文名repository，你可以简单理解成一个目录，这个目录里面的 所有文件都可以被Git管理起来，每个文件的修改、删除，Git都能跟踪，以便任何时刻都可以追踪历 史，或者在将来某个时刻可以“还原”。 暂存区 暂存区：英文叫stage, 或i ndex。一般存放在 &quot;.git目录下&quot; 下的i ndex文件（.git/index）中，所以我们 把暂存区有时也叫作索引（index）。 工作区 工作区：就是你在电脑里能看到的目录。 我对g it各分支的理解： 把分支归为三类： 1. 远程分支， 2. 本地远程分支（暂存提交后进入这 里）， 3.本地分支 当使用fetch, 或u pdate 时，会把远程分支的代码给更新到本地远程分支， 最后通过merge 把 本地远 程分支的代码给合并到本地分支。 同样，a dd,commit后进入本地远程分支， 最后push后再到远程分 支。 根据某个分支 创建新的分支： 以上命令指：以本地 master 分支为基准，创建 feature/test 分支并切换到该分支。 以上命令指： 以本地远端 master 分支为基准， 创建feature/test 分支，不切换 以上命令指：根据本地远端serverfix分支，新建一个本地serverfix分支，并保持跟踪关系。 拉取并合并代码： 以上指： 拉取所有origin分支的代码到本地远端分支。 如果加入具体分支名，则只更新具体的本地远 端分支 以上指： 当本地处于某一个分支时：执行以上命令后，就会把 本地远端分支的master代码，给合并到 当前分支，也可以合并 develop分支到本地分支。 以上命令不同于这个： 该命令：指的是把 本地m aster 分支合并到 当前分支来，上面的命令指的是把本地远端master分支 合 并到 当前分支， 本地远端分支 由 git fetch origin master 来保证最新 这里有三个分支概念： 本地分支， 本地远端分支， 远端分支。 本地分支指的就是开发人员所在的能 操作的分支； 本地远端分支，起到的是一个过渡的作用，可以作为合并远端分支的对象，也可以作为 创建本地分支的，代码基准。git fetch 命令获取到的代码更新就会更新到 本地远端分支，再由merge 操作来把本地远端分支的代码更新 合并到当前分支来。 删除分支（强制删除分支） 删除远端分支可用以下命令： 撤销操作： 以上命令指把 benchmarks.rb 文件从暂存状态恢复到未暂存的状态，但是之前修改的内容仍然存在， 不会丢失。这个仅仅只是撤销暂存区 该命令指的是：可以撤销到哪一个时间节点，对应的hash-id就好（--hard会丢失更改） 以上命令会把 未暂存的benchmarks.rb 文件 恢复到修改之前，会丢弃所有更改。 以上命令可以撤销，已提交的操作，之后重新编辑提交信息，再次commit（尽量少用）。 你在最后一条 commit 消息里有个笔误，已经执行了 git commit -m &quot;Fxies bug #42&quot;，但在 git push 之前你意识到消息应该是 “Fixes bug #42′′。 git commit --amend 会用一个新的 commit 更新并替换最近的 commit ，这个新的 commit 会把任何修 改内容和上一个 commit 的内容结合起来。如果当前没有提出任何修改，这个操作就只会把上次的 commit 消息重写一遍。 至于这几个参数： --mixed 意思是：不删除工作空间改动代码，撤销commit，并且撤销git add. 操作 这个为默认参数,git reset --mixed HEAD^ 和 git reset HEAD^ 效果是一样的。 --soft 不删除工作空间改动代码，撤销commit，不撤销git add . --hard 删除工作空间改动代码，撤销commit，撤销git add . 注意完成这个操作后，就恢复到了上一次的commit状态。 6. 删除文件 分段新增文件： 7. 建立关联 git本地新建一个分支后，必须要做远程分支关联。如果没有关联， git 会在下面的操作中提示你显示的 添加关联。关联目的是如果在本地分支下操作： git pull, git push ，不需要指定在命令行指定远程的分 支． 推送到远程分支后， 你只要没有显示指定，git pull 的时候，就会提示你。 解决办法是使用命令git branch --set-upstream 或者(git branch -u ) ;实例如下，其中debug为创建 的分支 上述命令：即将被GIT官方移除，官方推荐使用以下命令： 还可以使用：根据远端serverfix分支 新建一个本地serverfix分支，并保持跟踪关系、 如果想向同一个源名字， 添加不同的 push 地址，可以使用以下命令，目的在于每次push origin 的时 候， 就可以向两个地址，同时 Push 了。 当然也可以建立不同的源： 如下：新加了个 upstream 那么如何查看已经配置分支关联信息呢，通过下述三条命令均可： git branch -vv git remote show origin cat .git/config 推送本地分支到远端：以下命令仅为把当前分支推送到远端的test分支。相当于它说，“推送本地的 serverfix 分支，将其作为远程仓库的 serverfix 分支&quot; 如果想把当前test分支推送到远端另一个名字的分支，如test_2，则需要使用： 9. 查询是否需要更新代码。 9.1 若显示以下代码则说明当前分支的代码和远端对应的分支是相同提交，无需更新： 9.2 若显示以下代码，则说明当前分支落后于远端分支一个提交，提示信息已给出，可以使用Pull 来获 取对应的提交： 9.3 若显示以下代码，则说明之前还有一个未提交，需要提交上去（这种情况都很少，一般情况add 后，都会⻢上push） git储藏 ,储藏后，要恢复可使用： 查看日志信息 从图中可看出，这几个相关分支，在日志方面的动向，我当前的Head指针指向了我的开发分支，而我 现在的开发分支是和远端的develop， master是一样的。这说明我的分支还没有任何提交。而看到其 他分支都是在这几个hash-id的下方， 指的就是那几个分支落后于develop，如果是还没更新的代码， 则需要合并下最新的更新。 10.1 加对应参数：-p， 加了 -p后，就会显示每个提交的内容差异。 后面如果再加 -2(数字) 则，代 表查看两次提交的。 9.git 变基操作： 学习U RL： 整合分支最容易的方法是 merge 命令。 它会把两个分支的最新快照（C3 和 C4）以及二者最近的共同 祖先（C2）进行三方合并，合并的结果是生成一个新的快照（并提交）。 通过合并操作来整合分叉了的历史 其实，还有一种方法：你可以提取在 C4 中引入的补丁和修改，然后在 C3 的基础上应用一次。 在 Git 中，这种操作就叫做 变基。 你可以使用 rebase 命令将提交到某一分支上的所有修改都移至另一分支 上，就好像“重新播放”一样。 在上面这个例子中，运行： rebase master， 即把当前分支分支 experiment 分支修改的代码 变基到 master，即意味着 experiment 分支会把master分支的代码给合并过来，但是在log上，父节点为c3了，而 不是c 它的原理是首先找到这两个分支（即当前分支 experiment、变基操作的目标基底分支 master）的最近 共同祖先 C2，然后对比当前分支相对于该祖先的历次提交，提取相应的修改并存为临时文件，然后将 当前分支指向目标基底 C3, 最后以此将之前另存为临时文件的修改依序应用。（译注：写明了 commit id，以便理解，下同） Figure 37. 将 C4 中的修改变基到 C3 上 现在回到 master 分支，进行一次快进合并。 Figure 38. master 分支的快进合并 此时，C4' 指向的快照就和上面使用 merge 命令的例子中 C5 指向的快照一模一样了。 这两种整合方法 的最终结果没有任何区别，但是变基使得提交历史更加整洁。 你在查看一个经过变基的分支的历史记 录时会发现，尽管实际的开发工作是并行的，但它们看上去就像是串行的一样，提交历史是一条直线 没有分叉。 一般我们这样做的目的是为了确保在向远程分支推送时能保持提交历史的整洁——例如向某个其他人 维护的项目贡献代码时。 在这种情况下，你首先在自己的分支里进行开发，当开发完成时你需要先将 你的代码变基到 origin/master 上，然后再向主项目提交修改。 这样的话，该项目的维护者就不再需 要进行整合工作，只需要快进合并便可。 请注意，无论是通过变基，还是通过三方合并，整合的最终结果所指向的快照始终是一样的，只不过 提交历史不同罢了。 变基是将一系列提交按照原有次序依次应用到另一分支上，而合并是把最终结果 合在一起。 13.找回丢失的文件 展示所有 tracked 的文件 展示所有 untracked 的文件 展示所有忽略的文件 强制删除 untracked 的文件 可以用来删除新建的文件。如果不指定文件文件名，则清空所有工作的 untracked 文件。clean 命 令，注意两点： clean 后，删除的文件无法找回 不会影响 tracked 的文件的改动，只会删除 untracked 的文件 强制删除 untracked 的目录 可以用来删除新建的目录，注意：这个命令也可以用来删除 untracked 的文件。详情⻅上一条 展示简化的 commit 历史 把某一个分支到导出成一个文件 还可以搜索字符串 获取最新的标签 1 4. GIT 原理 14. 1 底层原理： ","link":"https://hzqyihui.github.io/post/git-xue-xi-bi-ji/"}]}